{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c852cc0",
   "metadata": {
    "id": "3c852cc0"
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.activation import ReLU\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    합성곱 연산, Batch Normalization, ReLU 활성함수를 연속적으로 거치도록 하는 Sequential을 return하는 함수\n",
    "\n",
    "    매개변수(Parameters)\n",
    "    ----------------------\n",
    "    in_channels: int형, 입력으로 들어오는 이미지의 채널 개수\n",
    "    out_channels: int형, 출력으로 반환할 이미지의 채널 개수\n",
    "    kernel_size: int 혹은 tuple 형, 사용할 필터의 크기 정보, default 값 3\n",
    "    stride: int 혹은 tuple 형, 스트라이드 값, defalut 값 1\n",
    "    padding: int 혹은 tuple 혹은 str형, 패딩에 대한 정보, defalut 값 0(패딩 없음)\n",
    "\n",
    "    반환 값(Returns)\n",
    "    ----------------------\n",
    "    합성곱 연산, Batch Normalization, ReLU 활성함수를 연속적으로 거치도록 하는 torch.nn.Sequential\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        # 입력받은 매개변수에 따라, 합성곱 연산을 진행\n",
    "         nn.Conv2d(in_channels,out_channels,kernel_size=kernel_size,\n",
    "                  stride=stride,padding=padding,bias=False),\n",
    "        # 배치 정규화 진행\n",
    "         nn.BatchNorm2d(out_channels) ,\n",
    "        # 활성함수인 ReLU 함수 거치기\n",
    "         nn.ReLU(inplace=True) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f1b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeparableConv2D(in_channels, out_channels, kernel=3):\n",
    "    \"\"\"\n",
    "    Separable Convolution 연산을 진행하는 Sequential을 return하는 함수\n",
    "\n",
    "    매개변수(Parameters)\n",
    "    ----------------------\n",
    "    in_channels: int형, 입력으로 들어오는 이미지의 채널 개수\n",
    "    out_channels: int형, 출력으로 반환할 이미지의 채널 개수\n",
    "    kernel: int 혹은 tuple 형, 사용할 필터의 크기 정보, default 값 3\n",
    "    \n",
    "    반환 값(Returns)\n",
    "    ----------------------\n",
    "    Separable Convolution 연산을 진행하는 Sequential\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        # 입력받은 채널의 개수를 보존하는 형태로, 채널 수가 1인 필터를 합성곱 연산\n",
    "         nn.Conv2d(in_channels,in_channels,kernel_size=kernel,\n",
    "                  stride=1,groups=in_channels,padding=1,bias=False),\n",
    "        # 1x1 합성곱 연산 진행, 채널 개수를 원하는 출력 채널 개수로 조정\n",
    "         nn.Conv2d(in_channels,out_channels,kernel_size=1,\n",
    "                  stride=1,bias=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0552673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualXceptionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    MiniXception 구조의 핵심인 부분으로, 잔차 연결로 두 경로의 계층 연산을 합해주는 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel=3):\n",
    "        \"\"\"\n",
    "        필요한 계층을 정의하는 부분들이 담긴 생성자(constructor)\n",
    "\n",
    "        매개변수(Parameters)\n",
    "        ----------------------\n",
    "        in_channels: int형, 입력으로 들어오는 이미지의 채널 개수\n",
    "        out_channels: int형, 출력으로 반환할 이미지의 채널 개수\n",
    "        kernel: int 혹은 tuple 형, 사용할 필터의 크기 정보, default 값 3\n",
    "        \"\"\"\n",
    "        # 상속받은 nn.Module 클래스의 생성자 호출\n",
    "        super().__init__()\n",
    "\n",
    "        # 그림 21에서, ResidualXceptionBlock을 구성하는 4개의 사각형 중 좌측 가장 하단\n",
    "        # 이 계층에서의 합성곱 연산을 통해 출력 데이터의 채널 수로 조정\n",
    "        # Separable convolution 연산을 진행하는 계층, Sequential 형태. 앞서 정의한 함수 활용\n",
    "        #여기에 코드 작성\n",
    "        self.depthwise_conv1=SeparableConv2D(in_channels,out_channels,kernel)\n",
    "        # 배치 정규화 진행\n",
    "        #여기에 코드 작성\n",
    "        self.bn1=nn.BatchNorm2d(out_channels)\n",
    "        # 활성함수로 ReLU 함수를 사용\n",
    "        #여기에 코드 작성\n",
    "        self.relu1=nn.ReLU(inplace=True)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "        self.dropout1=nn.Dropout2d(0.1)\n",
    "        # 그림 21에서, ResidualXceptionBlock을 구성하는 4개의 사각형 중 좌측 가운데\n",
    "        # 앞선 계층에서 출력 데이터의 채널 개수를 맞추었으므로, 채널 개수에는 변화를 주지 않음\n",
    "        # Separable convolution 연산을 진행하는 계층, Sequential 형태. 앞서 정의한 함수 활용\n",
    "        #여기에 코드 작성\n",
    "        self.depthwise_conv2=SeparableConv2D(out_channels,out_channels,kernel)\n",
    "        # 배치 정규화 진행\n",
    "        #여기에 코드 작성\n",
    "        self.bn2=nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 그림 21에서, ResidualXceptionBlock을 구성하는 4개의 사각형 중 좌측 상단\n",
    "        # 최대 풀링 진행\n",
    "        #여기에 코드 작성\n",
    "        \n",
    "        self.relu2=nn.ReLU(inplace=True)\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "        self.dropout2=nn.Dropout2d(0.1)\n",
    "        # 그림 21에서, ResidualXceptionBlock을 구성하는 4개의 사각형 중 우측\n",
    "        # 잔차 연결을 진행하기 위한 갈래의 계층을 구현\n",
    "        # 합성곱 연산 진행, 필요한 출력 데이터의 채널 수가 되도록 조정\n",
    "       #여기에 코드 작성\n",
    "        self.residual_conv=nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=1\n",
    "                                    ,padding=0,bias=False)\n",
    "        # 배치 정규화 진행\n",
    "        #여기에 코드 작성\n",
    "        self.residual_bn=nn.BatchNorm2d(out_channels)\n",
    "        self.residual_relu=nn.ReLU(inplace=True)\n",
    "        self.residual_maxpool=nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "        self.residual_dropout=nn.Dropout2d(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파를 진행하도록 하는 함수\n",
    "\n",
    "        매개변수(Parameters)\n",
    "        ----------------------\n",
    "        x: Tensor, 입력 데이터\n",
    "        \"\"\"\n",
    "        # 그림 21에서, ResidualXceptionBlock을 구성하는 두 갈래 중 우측\n",
    "        # 우측 갈래를 따른 순전파 진행 결과를 residual에 저장\n",
    "        #여기에 코드 작성\n",
    "        residual=self.residual_conv(x)\n",
    "        residual=self.residual_bn(residual)\n",
    "        residual=self.residual_relu(residual)\n",
    "        residual=self.residual_maxpool(residual)\n",
    "        residual=self.residual_dropout(residual)\n",
    "        # 그림 21에서, ResidualXceptionBlock을 구성하는 두 갈래 중 좌측\n",
    "        # 우측 갈래를 따른 순전파 진행 결과를 x에 저장\n",
    "        #여기에 코드 작성\n",
    "        x=self.depthwise_conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.maxpool1(x)\n",
    "        x=self.dropout1(x)\n",
    "        \n",
    "        \n",
    "        x=self.depthwise_conv2(x)\n",
    "        x=self.bn2(x)\n",
    "        x=self.relu2(x)\n",
    "        x=self.maxpool2(x)\n",
    "        x=self.dropout2(x)\n",
    "        # 두 갈래의 순전파 결과를 합한 Tensor 결과를 반환하여 잔차 연결 구현\n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mini_Xception(nn.Module):\n",
    "    \"\"\"\n",
    "    전체 MiniXception 구조를 구현한 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        필요한 계층을 정의하는 부분들이 담긴 생성자(constructor)\n",
    "        \"\"\"\n",
    "        # 상속받은 nn.Module 클래스의 생성자 호출\n",
    "        super().__init__()\n",
    "\n",
    "        # 그림 21에서, ResidualXceptionBlock 이전의 합성곱-배치 정규화-ReLU 계층\n",
    "        #여기에 코드 작성\n",
    "        self.conv1=conv_bn_relu(1,8,kernel_size=3,stride=1,padding=0)\n",
    "        self.conv2=conv_bn_relu(8,8,kernel_size=3,stride=1,padding=0)\n",
    "        # 그림 21에서, ResidualXceptionBlock 4개를 모아둔 부분\n",
    "        # 순전파가 진행될수록, 이미지 채널 개수를 2배씩 증가\n",
    "        # 이전 계층의 출력 채널 개수가 다음 채널의 입력 채널의 개수와 동일하도록 설정 필요\n",
    "        # 채널 개수를 증가시키는 점에 대한 기본적인 아이디어가 궁금하다면, VGGNet이라는 구조에 대해 찾아보자.\n",
    "        #여기에 코드 작성\n",
    "        \n",
    "        self.residual_blocks = nn.ModuleList([\n",
    "             ResidualXceptionBlock(8,16) ,\n",
    "             ResidualXceptionBlock(16,32) ,\n",
    "             ResidualXceptionBlock(32,64) ,\n",
    "             ResidualXceptionBlock(64,128)             \n",
    "        ])\n",
    "\n",
    "        # 그림 21에서, ResidualXceptionBlock 4개를 거친 이후의 부분\n",
    "        # 합성곱 계층\n",
    "        # Global Average Pooling 단계로 넘어가기 직전의 채널 수를 7로 설정함에 주목할 것.\n",
    "        #여기에 코드 작성\n",
    "        self.conv3=nn.Conv2d(128,7,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn3=nn.BatchNorm2d(7)\n",
    "        self.relu3=nn.ReLU(inplace=True)\n",
    "        self.maxpool3=nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "        self.dropout3=nn.Dropout2d(0.1)\n",
    "        \n",
    "        # Global Average Pooling 계층\n",
    "        #여기에 코드 작성\n",
    "        self.fc1=nn.Linear(7*44*44,1024)\n",
    "        self.fc_bn1=nn.BatchNorm1d(1024)\n",
    "        self.fc_relu1=nn.ReLU(inplace=True)\n",
    "        self.fc_maxpool1=nn.MaxPool1d(kernel_size=3,stride=1,padding=1)\n",
    "        self.fc_dropout1=nn.Dropout1d(0.1)\n",
    "        \n",
    "        \n",
    "        self.fc2=nn.Linear(1024,512)\n",
    "        self.fc_bn2=nn.BatchNorm1d(512)\n",
    "        self.fc_relu2=nn.ReLU(inplace=True)\n",
    "        self.fc_maxpool2=nn.MaxPool1d(kernel_size=3,stride=1,padding=1)\n",
    "        self.fc_dropout2=nn.Dropout1d(0.1)\n",
    "        \n",
    "        self.fc3=nn.Linear(512,7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파를 진행하도록 하는 함수\n",
    "\n",
    "        매개변수(Parameters)\n",
    "        ----------------------\n",
    "        x: Tensor, 입력 데이터\n",
    "        \"\"\"        \n",
    "        # 그림 21에서, ResidualXceptionBlock 이전의 순전파\n",
    "        #여기에 코드 작성\n",
    "        x=self.conv1(x)\n",
    "\n",
    "        x=self.conv2(x)\n",
    "\n",
    "        # 그림 21에서, ResidualXceptionBlock 4개에 대한 순전파\n",
    "        # ModuleList를 순회하면서, 저장된 계층들을 차례로 적용하도록 함\n",
    "        #여기에 코드 작성\n",
    "        for block in self.residual_blocks:\n",
    "            x=block(x)\n",
    "\n",
    "        # 그림 21에서, ResidualXceptionBlock 이후의 합성곱 계층\n",
    "        #여기에 코드 작성\n",
    "        x=self.conv3(x)\n",
    "        x=self.bn3(x)\n",
    "        x=self.relu3(x)\n",
    "        x=self.maxpool3(x)\n",
    "        x=self.dropout3(x)\n",
    "        # 그림 21에서, Global Average Pooling\n",
    "        #여기에 코드 작성\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.fc1(x)\n",
    "        x=self.fc_bn1(x)\n",
    "        x=self.fc_relu1(x)\n",
    "        x=self.fc_maxpool1(x)\n",
    "        x=self.fc_dropout1(x)\n",
    "        \n",
    "        \n",
    "        x=self.fc2(x)\n",
    "        x=self.fc_bn2(x)\n",
    "        x=self.fc_relu2(x)\n",
    "        x=self.fc_maxpool2(x)\n",
    "        x=self.fc_dropout2(x)\n",
    "        \n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da96a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*1*1,128)\n",
    "        self.fc2 = nn.Linear(128,128)\n",
    "        self.fc3=nn.Linear(128,7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #여기에 코드 작성\n",
    "        x=self.conv1(x)\n",
    "\n",
    "        x=self.conv2(x)\n",
    "\n",
    "        x=self.conv3(x)\n",
    "\n",
    "        x=self.conv4(x)\n",
    "        x=self.conv5(x)\n",
    "        x=self.flatten(x)\n",
    "\n",
    "        x=self.fc1(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f10a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            #3 224 224\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.1),\n",
    "            #64 112 64\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #128 56 32\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.1),\n",
    "            #256 28 16\n",
    "            nn.Conv2d(256, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.1),\n",
    "            #512 14 8\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7)\n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        \n",
    "        #512 1 1\n",
    "        self.fc = nn.Linear(512,7)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x=self.avg_pool(x)\n",
    "        x=self.flatten(x)\n",
    "        x=self.fc(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc4bc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (1.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary as summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2eb552d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 7, 7])\n",
      "torch.Size([2, 512, 1, 1])\n",
      "torch.Size([2, 512])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]             640\n",
      "         LeakyReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "         LeakyReLU-4         [-1, 64, 224, 224]               0\n",
      "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
      "         MaxPool2d-6         [-1, 64, 112, 112]               0\n",
      "         Dropout2d-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
      "         LeakyReLU-9        [-1, 128, 112, 112]               0\n",
      "           Conv2d-10        [-1, 128, 112, 112]         147,584\n",
      "        LeakyReLU-11        [-1, 128, 112, 112]               0\n",
      "      BatchNorm2d-12        [-1, 128, 112, 112]             256\n",
      "        MaxPool2d-13          [-1, 128, 56, 56]               0\n",
      "           Conv2d-14          [-1, 256, 56, 56]         295,168\n",
      "        LeakyReLU-15          [-1, 256, 56, 56]               0\n",
      "           Conv2d-16          [-1, 256, 56, 56]         590,080\n",
      "        LeakyReLU-17          [-1, 256, 56, 56]               0\n",
      "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
      "        LeakyReLU-19          [-1, 256, 56, 56]               0\n",
      "      BatchNorm2d-20          [-1, 256, 56, 56]             512\n",
      "        MaxPool2d-21          [-1, 256, 28, 28]               0\n",
      "        Dropout2d-22          [-1, 256, 28, 28]               0\n",
      "           Conv2d-23          [-1, 512, 28, 28]       1,180,160\n",
      "        LeakyReLU-24          [-1, 512, 28, 28]               0\n",
      "           Conv2d-25          [-1, 512, 28, 28]       2,359,808\n",
      "        LeakyReLU-26          [-1, 512, 28, 28]               0\n",
      "           Conv2d-27          [-1, 512, 28, 28]       2,359,808\n",
      "        LeakyReLU-28          [-1, 512, 28, 28]               0\n",
      "      BatchNorm2d-29          [-1, 512, 28, 28]           1,024\n",
      "        MaxPool2d-30          [-1, 512, 14, 14]               0\n",
      "        Dropout2d-31          [-1, 512, 14, 14]               0\n",
      "           Conv2d-32          [-1, 512, 14, 14]       2,359,808\n",
      "        LeakyReLU-33          [-1, 512, 14, 14]               0\n",
      "           Conv2d-34          [-1, 512, 14, 14]       2,359,808\n",
      "        LeakyReLU-35          [-1, 512, 14, 14]               0\n",
      "           Conv2d-36          [-1, 512, 14, 14]       2,359,808\n",
      "        LeakyReLU-37          [-1, 512, 14, 14]               0\n",
      "      BatchNorm2d-38          [-1, 512, 14, 14]           1,024\n",
      "        MaxPool2d-39            [-1, 512, 7, 7]               0\n",
      "        Dropout2d-40            [-1, 512, 7, 7]               0\n",
      "        AvgPool2d-41            [-1, 512, 1, 1]               0\n",
      "          Flatten-42                  [-1, 512]               0\n",
      "           Linear-43                    [-1, 7]           3,591\n",
      "================================================================\n",
      "Total params: 14,720,071\n",
      "Trainable params: 14,720,071\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 273.72\n",
      "Params size (MB): 56.15\n",
      "Estimated Total Size (MB): 330.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "    model = VGG16().to(device)\n",
    "    summary(model,(1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763ed0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vision_model_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
